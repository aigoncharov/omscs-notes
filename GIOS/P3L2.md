# Memory management

## Goals

Manage DRAM (physical memory) on behalf of the processes. Virtual mem size might be larger than physical mem size.
OS must be able:
- allocate (allocate, replace)
- arbitrate (address translation and validation)

Page-base memory management:
- allocate = page (virtual) -> page frames (physical)
- arbitrate = page tables

Segment-based memory management:
- allocate = segments
- arbitrate = segment registers

## H/W support:
- MMU (memory management unit). Translates virtual -> physical. Generates faults (illegal access, permissions, not found)
- registers (pointers to page tables, number of segments)
- cache - translation lookaside buffer (TLB). valid virtual -> physical translations

## Page-based management

Virtual page size == physical page size. Virtual address =  virtual page number (VPN) + offset. Physical address =  physical frame number (PFN) + offset. 
Table is created per process. CPU register (CR3 on x86) points to the current context table. Physical memory allocated on first touch. Unused pages reclaimed. Table has `valid bit` (`present bit`). 

Generic page table entry:
| PFN | ... | X | W | R | A | D | P |
P - present
D - dirty (written to)
A - accessed
XWR - permissions

x86 page table entry:
| PFN | ... | G | PAT | D | A | PCD | PWT | U/S | R/W | P |
P - present
D - dirty
A - accessed
R/W - permissions. 0 = R, 1 = R&W
U/S - permissions. 0 = usermode, 1 = supervisor
others - caching info (write thourhg, caching disabled, etc)
... - reserved for future

MMU uses flags to determine the validity of the address. For invalid entries it traps into kernel. Page fault handler takes over. Possible actions: bring page from disk, protection error, etc. On x86 faulting addr is tored in CR3 register.

### Hierarchical page tables 

Save space. On 64bit architectures flat page table needs to map to potentially lots of memory. So page table size is also large. Solution: create a page table of page tables. If needed, add additional levels of outer page tables.
Address structure:
| P1 | ... | PN | offset |

Overhead - N additional memory accesses to get the final address. Solution: translation look-aside buffer (TLB) = address translation cache. Can be per core or shared.

### Inverted page tables

Reason: physical memory much smaller than virtual memory
Virtual (logical) address: | pid | virtual page number (p) | offset (d) |
Table: array of | pid | p | physical page number (i) |
Physical address: | i | d |
Problem: Linear search for | pid | p | pair in the table
Solution: hash table

## Segmentation

Arbitrary granularity. Correspond to logical components e.g. code, heap, data, etc.

| selector | offset |----------|
  |                            |
  |  | descriptor table   |    |
  |  |--------------------|    |
  |->| segment descriptor |--> +
                               |
                               v
                               32 bit linear address

Segment size = base + limit registers

### Segmentation + paging           

     logical address                    linear address               physical address
cpu ----------------> segmentation unit --------------> paging unit ------------------> physical memory

x86_32 = paging + segmentation
x86_64 = paging

## Page size

Linux/x86: 4kB (offset 10 bits), 2MB (large, offset 21 bits), 1GB (huge, offset 30 bits)
Larger pages:
+ fewer entries, smaller tables, TLB hits
- internal fragmentation

## Memory allocation

Determines VA (virtual address) to PA (physical address) mapping.

- kernel level: kernel state, static process state, free memory
- user level: dynamic process state (heap)

Challenge - fragmentation.
Buddy allocator - subdivide into 2^x chunks and find the smallest chunk that satisfies

Example (request for 16)
--|--|--|
  |  |  |
  |32|32|
  |  |  |
64|--|--|
  |  |16|
  |32|--|
  |  |xx|
--|--|--|

Slab allocator - caches for common object sizes, i.e. allocate a `slab` (chunk of memory) for which fits several 3KB objects. Replace the objects as needed. Allocate new slabs as needed.

## Freeing memory

When:
- memory usage above threshold
- cpu usage below threshold
Which:
- pages that won't be used - least-recently used (LRU) (access bit to track reference)
- pages that don't need to be written out (dirty bit)
- avoid non-swappable

## H/W optimizations

### Copy-on-write

On create:
- map new VA to the original page
- write protect the page
- on write page fault and copy
Result: if read-only - save memory and CPU time

### Checkpointing

- write-protect and copy process state
- do not stop the process, let it mark pages as dirtied
- copy the diffs
